{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "zZ8lS-UAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Yupeng Su", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=zZ8lS-UAAAAJ&citpid=4", "affiliation": "University of California, Santa Barbara", "organization": 13303172519087716448, "interests": ["Efficient LLMs", "Edge Deployment", "Quantization", "Sparsity"], "email_domain": "@ucsb.edu", "homepage": "https://yupengsu.github.io/", "citedby": 20, "publications": {"zZ8lS-UAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aptq: Attention-aware post-training mixed-precision quantization for large language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:u5HHmVD_uO8C", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15244685732902575826", "cites_id": ["15244685732902575826"]}, "zZ8lS-UAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Edgellm: A highly efficient cpu-fpga heterogeneous edge accelerator for large language models", "pub_year": "2025"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:9yKSN-GCB0IC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3853470651164090470", "cites_id": ["3853470651164090470"]}, "zZ8lS-UAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for Large Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:u-x6o8ySG0sC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15020194694696804214", "cites_id": ["15020194694696804214"]}, "zZ8lS-UAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization Degradation for Mathematical Reasoning", "pub_year": "2025"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:d1gkVwhDpl0C", "num_citations": 0}}, "citedby5y": 20, "hindex": 2, "hindex5y": 2, "i10index": 1, "i10index5y": 1, "cites_per_year": {"2023": 1, "2024": 12, "2025": 7}, "updated": "2025-03-22 08:11:51.923161"}