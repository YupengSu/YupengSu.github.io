{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "zZ8lS-UAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Yupeng Su", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=zZ8lS-UAAAAJ&citpid=4", "affiliation": "PhD Student of Computer Science, UC Santa Barbara", "organization": 13303172519087716448, "interests": ["Efficient LLMs", "Edge Deployment", "Quantization", "Sparsity"], "email_domain": "@ucsb.edu", "homepage": "https://yupengsu.github.io/", "citedby": 103, "publications": {"zZ8lS-UAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aptq: Attention-aware post-training mixed-precision quantization for large language models", "pub_year": "2024", "citation": "Proceedings of the 61st ACM/IEEE Design Automation Conference, 1-6, 2024"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:u5HHmVD_uO8C", "num_citations": 49, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15244685732902575826", "cites_id": ["15244685732902575826"]}, "zZ8lS-UAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Edgellm: A highly efficient cpu-fpga heterogeneous edge accelerator for large language models", "pub_year": "2025", "citation": "IEEE Transactions on Circuits and Systems I: Regular Papers, 2025"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:9yKSN-GCB0IC", "num_citations": 36, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14255700488493382617", "cites_id": ["14255700488493382617"]}, "zZ8lS-UAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Quantization meets reasoning: Exploring llm low-bit quantization degradation for mathematical reasoning", "pub_year": "2025", "citation": "arXiv preprint arXiv:2501.03035, 2025"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:d1gkVwhDpl0C", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7071126316140768742", "cites_id": ["7071126316140768742"]}, "zZ8lS-UAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "InfiJanice: Joint Analysis and In-situ Correction Engine for Quantization-Induced Math Degradation in Large Language Models", "pub_year": "2025", "citation": "arXiv preprint arXiv:2505.11574, 2025"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:2osOgNQ5qMEC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10894085082482619829", "cites_id": ["10894085082482619829"]}, "zZ8lS-UAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LLM-barber: Block-aware rebuilder for sparsity mask in one-shot for large language models", "pub_year": "2024", "citation": "arXiv preprint arXiv:2408.10631, 2024"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:u-x6o8ySG0sC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15020194694696804214", "cites_id": ["15020194694696804214"]}, "zZ8lS-UAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models", "pub_year": "2025", "citation": "arXiv preprint arXiv:2509.16989, 2025"}, "filled": false, "author_pub_id": "zZ8lS-UAAAAJ:qjMakFHDy7sC", "num_citations": 0}}, "citedby5y": 101, "hindex": 3, "hindex5y": 3, "i10index": 3, "i10index5y": 3, "cites_per_year": {"2024": 17, "2025": 83}, "updated": "2025-12-22 17:21:31.884349"}